# Libraries Used
- NLTK
- genism
- pattern

# Tokenize Text Data
When we deal with text, we need to break it down into smaller pieces for analysis. This is
where tokenization comes into the picture. It is the process of dividing the input text into a
set of pieces like words or sentences. These pieces are called tokens.
